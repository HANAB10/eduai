
import { NextRequest, NextResponse } from 'next/server'
import { extractVoiceFeatures, VoicePrint } from '@/lib/deepgram'
import { deepgram, transcriptionConfig } from '@/lib/deepgram'
import { voicePrintService } from '@/lib/database'

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData()
    const audioFile = formData.get('audio') as File
    const userId = formData.get('userId') as string
    const userName = formData.get('userName') as string

    if (!audioFile || !userId || !userName) {
      return NextResponse.json({ error: 'Audio file, userId and userName are required' }, { status: 400 })
    }

    console.log(`Starting voice calibration for ${userName} (${userId})`)

    // è½¬æ¢éŸ³é¢‘ä¸º ArrayBuffer
    const audioBuffer = await audioFile.arrayBuffer()
    console.log(`Audio file size: ${audioBuffer.byteLength} bytes`)
    
    if (!deepgram) {
      return NextResponse.json({ error: 'Deepgram not configured' }, { status: 500 })
    }

    // ä½¿ç”¨ Deepgram è¿›è¡Œè¯­éŸ³è¯†åˆ«ä»¥éªŒè¯å½•éŸ³è´¨é‡
    const { result, error } = await deepgram.listen.prerecorded.transcribeFile(
      Buffer.from(audioBuffer),
      {
        ...transcriptionConfig,
        model: 'nova-2',
        language: 'en-US',
      }
    )

    if (error) {
      console.error('Deepgram transcription error:', error)
      return NextResponse.json({ error: 'Voice recognition failed' }, { status: 500 })
    }

    const transcript = result.results.channels[0].alternatives[0].transcript

    // æå–è¯­éŸ³ç‰¹å¾
    const voicePrint = await extractVoiceFeatures(new Blob([audioBuffer]), userId)
    
    // å­˜å‚¨è¯­éŸ³ç‰¹å¾åˆ°æ•°æ®åº“
    await voicePrintService.saveVoicePrint({
      user_id: userId,
      features: voicePrint.features,
      sample_rate: voicePrint.sampleRate,
      duration: voicePrint.duration,
      transcript: transcript
    })

    // èŽ·å–æ€»çš„æ ¡å‡†ç”¨æˆ·æ•°
    const allVoicePrints = await voicePrintService.getAllVoicePrints()

    console.log(`âœ… Voice calibration completed for ${userName} (${userId})`)
    console.log(`ðŸ“ Transcript: "${transcript}"`)
    console.log(`ðŸ‘¥ Total calibrated users: ${allVoicePrints.length}`)

    return NextResponse.json({
      success: true,
      userId,
      userName,
      transcript,
      message: 'Voice calibration completed successfully',
      totalCalibratedUsers: allVoicePrints.length
    })

  } catch (error) {
    console.error('Voice calibration error:', error)
    return NextResponse.json({ error: 'Voice calibration failed' }, { status: 500 })
  }
}

// èŽ·å–æ‰€æœ‰å·²æ ¡å‡†çš„è¯­éŸ³ç‰¹å¾
export async function GET() {
  try {
    const voicePrints = await voicePrintService.getAllVoicePrints()
    
    const calibratedUsers = voicePrints.map(vp => ({
      userId: vp.user_id,
      userName: vp.first_name && vp.last_name ? `${vp.first_name} ${vp.last_name}` : `User ${vp.user_id}`,
      timestamp: vp.created_at,
      duration: vp.duration,
      transcript: vp.transcript
    }))

    return NextResponse.json({
      calibratedUsers,
      count: calibratedUsers.length
    })
  } catch (error) {
    console.error('Error fetching voice prints:', error)
    return NextResponse.json({ error: 'Failed to fetch voice calibration data' }, { status: 500 })
  }
}
